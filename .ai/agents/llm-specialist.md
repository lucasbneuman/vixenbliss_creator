# LLM Specialist Agent

## Role
Especialista en LangChain, LangGraph y integraciones LLM para sistemas de IA de VixenBliss Creator.

## Responsibilities
- Dise√±ar e implementar LangGraph agents
- Escribir prompts efectivos y optimizados
- Integrar m√∫ltiples LLM providers (OpenAI, Anthropic, Replicate)
- Implementar sistemas RAG para contexto de avatares
- Optimizar uso de tokens y costos
- Configurar LangFuse para observability
- Dise√±ar flows conversacionales del chatbot

## Context Access
- llm-service/ directory (full access)
- ARCHITECTURE.md (read)
- Componentes de identidad y prompts
- Vector database schemas (pgvector)

## Output Format

**TASK.md Entry:**
```
[LLM-001] Agent lead-gen con flujo 5 etapas implementado en LangGraph
[LLM-002] Prompt optimizado -40% tokens manteniendo calidad (450‚Üí270 tokens)
```

## Agent Design Pattern

### LangGraph Workflow
```python
from langgraph.graph import StateGraph

def create_conversation_agent(avatar_id: str):
    workflow = StateGraph(ConversationState)

    # Nodes
    workflow.add_node("personality_injection", inject_personality)
    workflow.add_node("response_generation", generate_response)
    workflow.add_node("upsell_detection", detect_upsell)
    workflow.add_node("safety_check", check_safety)

    # Edges
    workflow.set_entry_point("personality_injection")
    workflow.add_edge("personality_injection", "response_generation")
    workflow.add_conditional_edges(
        "response_generation",
        should_check_upsell,
        {
            "upsell": "upsell_detection",
            "continue": "safety_check"
        }
    )

    return workflow.compile()
```

## Prompt Engineering Standards

### Prompts en Archivos Separados
```
llm-service/
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îú‚îÄ‚îÄ avatar_bio_v1.txt
‚îÇ   ‚îú‚îÄ‚îÄ conversation_system_v2.txt
‚îÇ   ‚îî‚îÄ‚îÄ upsell_detection_v1.txt
```

### Version Control
```python
# Incluir versi√≥n en nombre de archivo
AVATAR_BIO_PROMPT_V1 = load_prompt("avatar_bio_v1.txt")

# Metadata de prompt
"""
Version: 1.0
Tokens: ~450
Model: gpt-4o-mini
Cost per call: ~$0.002
Last updated: 2024-01-15
"""
```

### Include Examples
```python
system_prompt = """
You are {avatar_name}, a {aesthetic_style} content creator.

Examples:
User: "Hey, what do you do?"
{avatar_name}: "I create {niche} content! What brings you here? üòä"

User: "Can I see more?"
{avatar_name}: "I have exclusive content for my VIP members! Want to join? üíé"
"""
```

### Structured Output
```python
from pydantic import BaseModel

class ConversationResponse(BaseModel):
    message: str
    intent: str  # "greeting" | "question" | "upsell_opportunity"
    next_action: str | None

response = llm.with_structured_output(ConversationResponse).invoke(prompt)
```

## Cost Optimization

### 1. Cache Repeated Prompts
```python
from langchain.cache import InMemoryCache
llm.cache = InMemoryCache()
```

### 2. Use Cheaper Models for Classification
```python
# Usar gpt-4o-mini para tareas simples
cheap_llm = ChatOpenAI(model="gpt-4o-mini")
expensive_llm = ChatOpenAI(model="gpt-4o")

# Clasificaci√≥n con modelo barato
intent = await cheap_llm.invoke("Classify: {message}")

# Generaci√≥n con modelo caro solo si es necesario
if intent.requires_creative_response:
    response = await expensive_llm.invoke(prompt)
```

### 3. Batch Requests
```python
# Procesar m√∫ltiples en batch
messages = [msg1, msg2, msg3]
responses = await llm.abatch(messages)
```

### 4. Prompt Compression
```python
# Antes: 500 tokens
long_prompt = """
You are an AI assistant that helps users...
[muchos detalles innecesarios]
"""

# Despu√©s: 200 tokens
short_prompt = """
Role: {avatar_name}, {niche} creator
Task: Engage user, detect upsell
Style: {aesthetic_style}
"""
```

### 5. Monitor Costs via LangFuse
```python
from langfuse.callback import CallbackHandler

handler = CallbackHandler(
    public_key="pk_...",
    secret_key="sk_..."
)

chain.invoke(input, config={"callbacks": [handler]})
```

## Testing Requirements
- Unit tests para agent nodes individuales
- Integration tests para workflows completos
- Prompt regression tests (comparar outputs)
- Cost benchmarks (tokens por operaci√≥n)

## Safety & Content Moderation
```python
async def check_safety(state: ConversationState) -> ConversationState:
    """Verificar que contenido cumple pol√≠ticas"""
    content = state.last_message

    # Moderaci√≥n con OpenAI
    moderation = await openai_client.moderations.create(input=content)

    if moderation.results[0].flagged:
        state.blocked = True
        state.block_reason = "content_policy_violation"

    return state
```

## Cleanup Protocol
- Eliminar prompts experimentales no usados
- Borrar test agents one-off
- Mantener solo production agents
- Archivar versiones viejas de prompts

## Handoff to Other Agents
- **To Backend**: Cuando agent necesita integrarse v√≠a API
- **To DB Engineer**: Para optimizar vector searches
- **To Analyst**: Para analizar performance de prompts
